import time
import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Optional deps
try:
    import tushare as ts
except Exception:
    ts = None

try:
    import baostock as bs
except Exception:
    bs = None

# -----------------------------
# Basic page config
# -----------------------------
st.set_page_config(
    page_title="Aè‚¡æ·±åº¦å¤ç›˜ç³»ç»Ÿ Pro",
    layout="wide",
    page_icon="ğŸ“ˆ"
)

# -----------------------------
# Data helpers
# -----------------------------
def _to_ts_code(symbol: str) -> str:
    """è½¬æ¢ä¸º Tushare æ‰€éœ€çš„æ ¼å¼ (e.g., 600519.SH)"""
    symbol = symbol.strip()
    if symbol.endswith(".SH") or symbol.endswith(".SZ"):
        return symbol
    if symbol.isdigit():
        return f"{symbol}.SH" if symbol.startswith("6") else f"{symbol}.SZ"
    return symbol

def _to_bs_code(symbol: str) -> str:
    """è½¬æ¢ä¸º Baostock æ‰€éœ€çš„æ ¼å¼ (e.g., sh.600519)"""
    symbol = symbol.strip()
    # å¦‚æœå·²ç»æ˜¯ sh. æˆ– sz. å¼€å¤´ï¼Œç›´æ¥è¿”å›
    if symbol.startswith("sh.") or symbol.startswith("sz."):
        return symbol
    # å¦‚æœæ˜¯ Tushare æ ¼å¼ (600519.SH)ï¼Œè½¬ä¸º sh.600519
    if symbol.endswith(".SH"):
        return f"sh.{symbol[:6]}"
    if symbol.endswith(".SZ"):
        return f"sz.{symbol[:6]}"
    # çº¯æ•°å­—
    if symbol.isdigit():
        return f"sh.{symbol}" if symbol.startswith("6") else f"sz.{symbol}"
    return symbol

@st.cache_data(ttl=60 * 60 * 24) # ç¼“å­˜ä¸€å¤©
def get_stock_name(symbol: str, token: str = "") -> str:
    """
    ç»Ÿä¸€è·å–è‚¡ç¥¨åç§°ï¼š
    1. ä¼˜å…ˆå°è¯• Tushare (å¦‚æœæä¾›äº† Token)
    2. å¤±è´¥æˆ–æ—  Token åˆ™å°è¯• Baostock
    3. éƒ½å¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    name = ""
    
    # --- å°è¯• Tushare ---
    if token and ts is not None:
        try:
            ts_code = _to_ts_code(symbol)
            pro = ts.pro_api(token)
            # åªæŸ¥è¯¢å•åªè‚¡ç¥¨ï¼Œé€Ÿåº¦å¿«
            df = pro.stock_basic(ts_code=ts_code, fields='name')
            if not df.empty:
                return df.iloc[0]['name']
        except Exception:
            pass # Tushare å¤±è´¥ï¼Œé™é»˜è¿›å…¥ Baostock

    # --- å°è¯• Baostock ---
    if bs is not None:
        try:
            bs_code = _to_bs_code(symbol)
            # ç™»å½•
            lg = bs.login()
            if lg.error_code == '0':
                rs = bs.query_stock_basic(code=bs_code)
                if rs.error_code == '0':
                    row = rs.get_row_data()
                    # Baostock è¿”å›çš„ list é¡ºåº: [code, code_name, ipoDate, outDate, type, status]
                    if row and len(row) > 1:
                        name = row[1]
            bs.logout()
        except Exception:
            pass

    return name

@st.cache_data(ttl=60 * 15, show_spinner=False)
def fetch_hist_tushare(symbol: str, token: str, days: int = 180,
                       adjust: str = "qfq", retry: int = 3) -> pd.DataFrame:
    """TuShare daily bars with optional qfq/hfq adjustment using adj_factor."""
    if ts is None or not token:
        return pd.DataFrame()

    pro = ts.pro_api(token)
    end = pd.Timestamp.today().strftime("%Y%m%d")
    start = (pd.Timestamp.today() - pd.Timedelta(days=days * 3)).strftime("%Y%m%d")

    ts_code = _to_ts_code(symbol)

    last_err = None
    for _ in range(retry):
        try:
            df = pro.daily(ts_code=ts_code, start_date=start, end_date=end)
            if df is None or df.empty:
                return pd.DataFrame()

            # adj factors
            if adjust in ("qfq", "hfq"):
                af = pro.adj_factor(ts_code=ts_code, start_date=start, end_date=end)
                if af is not None and not af.empty:
                    af = af.rename(columns={"trade_date": "date", "adj_factor": "factor"})
                    df = df.merge(af[["date", "factor"]], on="date", how="left")
                    df["factor"] = df["factor"].ffill().bfill()

                    if adjust == "qfq":
                        df["adj"] = df["factor"] / df["factor"].iloc[-1]
                    else:  # hfq
                        df["adj"] = df["factor"] / df["factor"].iloc[0]

                    for col in ["open", "high", "low", "close"]:
                        df[col] = df[col] * df["adj"]

            df = df.rename(columns={
                "trade_date": "date",
                "vol": "volume",
                "pct_chg": "pct_change"
            })
            df["date"] = pd.to_datetime(df["date"])
            for col in ["open", "high", "low", "close", "volume", "amount", "pct_change"]:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors="coerce")
            df = df.sort_values("date").reset_index(drop=True).tail(days)
            return df[["date","open","high","low","close","volume","amount","pct_change"]]
        except Exception as e:
            last_err = e
            time.sleep(1.0)

    raise last_err

@st.cache_data(ttl=60 * 15, show_spinner=False)
def fetch_hist_baostock(symbol: str, days: int = 180, adjust: str = "qfq") -> pd.DataFrame:
    """Baostock daily bars; adjustflag supports qfq/hfq/no."""
    if bs is None:
        return pd.DataFrame()

    lg = bs.login()
    if lg.error_code != "0":
        bs.logout()
        return pd.DataFrame()

    end = pd.Timestamp.today()
    start = end - pd.Timedelta(days=days * 3)

    code = _to_bs_code(symbol) # ä½¿ç”¨æ–°çš„è½¬æ¢å‡½æ•°

    adj_flag = "3"
    if adjust == "qfq":
        adj_flag = "2"
    elif adjust == "hfq":
        adj_flag = "1"

    rs = bs.query_history_k_data_plus(
        code,
        "date,open,high,low,close,volume,amount,pctChg",
        start_date=start.strftime("%Y-%m-%d"),
        end_date=end.strftime("%Y-%m-%d"),
        frequency="d",
        adjustflag=adj_flag
    )

    data = []
    while rs.error_code == "0" and rs.next():
        data.append(rs.get_row_data())

    bs.logout()

    if not data:
        return pd.DataFrame()

    df = pd.DataFrame(data, columns=rs.fields)
    df = df.rename(columns={"pctChg": "pct_change"})
    df["date"] = pd.to_datetime(df["date"])
    for col in ["open","high","low","close","volume","amount","pct_change"]:
        df[col] = pd.to_numeric(df[col], errors="coerce")
    df = df.sort_values("date").reset_index(drop=True).tail(days)
    return df

def fetch_hist(symbol: str, token: str, days: int = 180, adjust: str = "qfq") -> pd.DataFrame:
    """Unified entry: tushare -> baostock fallback."""
    if token:
        try:
            df = fetch_hist_tushare(symbol, token, days=days, adjust=adjust)
            if df is not None and not df.empty:
                return df
        except Exception as e:
            st.warning(f"TuShare æ‹‰å–å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢ Baostockï¼š{e}")
    return fetch_hist_baostock(symbol, days=days, adjust=adjust)

# -----------------------------
# Indicator functions
# -----------------------------
def calc_indicators(df: pd.DataFrame) -> pd.DataFrame:
    close = df["close"]
    high = df["high"]
    low = df["low"]
    vol = df["volume"]

    # SMA / EMA
    for n in [5, 10, 20, 60, 120]:
        df[f"MA{n}"] = close.rolling(n).mean()
        df[f"EMA{n}"] = close.ewm(span=n, adjust=False).mean()

    # Bollinger
    mid = df["MA20"]
    std = close.rolling(20).std()
    df["Upper"] = mid + 2 * std
    df["Lower"] = mid - 2 * std

    # RSI
    delta = close.diff()
    gain = delta.clip(lower=0).rolling(14).mean()
    loss = (-delta.clip(upper=0)).rolling(14).mean()
    rs = gain / (loss + 1e-9)
    df["RSI"] = 100 - (100 / (1 + rs))

    # StochRSI
    rsi_min = df["RSI"].rolling(14).min()
    rsi_max = df["RSI"].rolling(14).max()
    df["StochRSI"] = (df["RSI"] - rsi_min) / (rsi_max - rsi_min + 1e-9)

    # MACD
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    df["DIF"] = ema12 - ema26
    df["DEA"] = df["DIF"].ewm(span=9, adjust=False).mean()
    df["HIST"] = df["DIF"] - df["DEA"]

    # KDJ (stochastic)
    low_n = low.rolling(9).min()
    high_n = high.rolling(9).max()
    rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
    df["K"] = rsv.ewm(com=2).mean()
    df["D"] = df["K"].ewm(com=2).mean()
    df["J"] = 3 * df["K"] - 2 * df["D"]

    # ATR
    tr = pd.concat([
        high - low,
        (high - close.shift()).abs(),
        (low - close.shift()).abs()
    ], axis=1).max(axis=1)
    df["ATR14"] = tr.rolling(14).mean()

    # ADX
    up_move = high.diff()
    down_move = -low.diff()
    plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0.0)
    minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0.0)
    tr14 = tr.rolling(14).sum()
    plus_di = 100 * pd.Series(plus_dm, index=df.index).rolling(14).sum() / (tr14 + 1e-9)
    minus_di = 100 * pd.Series(minus_dm, index=df.index).rolling(14).sum() / (tr14 + 1e-9)
    dx = (abs(plus_di - minus_di) / (plus_di + minus_di + 1e-9)) * 100
    df["ADX"] = dx.rolling(14).mean()
    df["PLUS_DI"] = plus_di
    df["MINUS_DI"] = minus_di

    # OBV
    direction = np.sign(close.diff()).fillna(0)
    df["OBV"] = (direction * vol).cumsum()

    # CCI
    tp = (high + low + close) / 3
    ma_tp = tp.rolling(20).mean()
    md = (tp - ma_tp).abs().rolling(20).mean()
    df["CCI"] = (tp - ma_tp) / (0.015 * md + 1e-9)

    # MFI
    raw_mf = tp * vol
    pos_mf = raw_mf.where(tp.diff() > 0, 0).rolling(14).sum()
    neg_mf = raw_mf.where(tp.diff() < 0, 0).rolling(14).sum()
    mfr = pos_mf / (neg_mf + 1e-9)
    df["MFI"] = 100 - (100 / (1 + mfr))

    # Ichimoku (9,26,52)
    tenkan = (high.rolling(9).max() + low.rolling(9).min()) / 2
    kijun = (high.rolling(26).max() + low.rolling(26).min()) / 2
    span_a = ((tenkan + kijun) / 2).shift(26)
    span_b = ((high.rolling(52).max() + low.rolling(52).min()) / 2).shift(26)
    df["TENKAN"] = tenkan
    df["KIJUN"] = kijun
    df["SPAN_A"] = span_a
    df["SPAN_B"] = span_b

    # Parabolic SAR (simplified)
    af = 0.02
    max_af = 0.2
    sar = close.copy()
    trend = 1
    ep = low.iloc[0]
    sar.iloc[0] = low.iloc[0]
    for i in range(1, len(df)):
        prev_sar = sar.iloc[i-1]
        if trend == 1:
            sar.iloc[i] = prev_sar + af * (ep - prev_sar)
            if low.iloc[i] < sar.iloc[i]:
                trend = -1
                sar.iloc[i] = ep
                ep = high.iloc[i]
                af = 0.02
            else:
                if high.iloc[i] > ep:
                    ep = high.iloc[i]
                    af = min(af + 0.02, max_af)
        else:
            sar.iloc[i] = prev_sar + af * (ep - prev_sar)
            if high.iloc[i] > sar.iloc[i]:
                trend = 1
                sar.iloc[i] = ep
                ep = low.iloc[i]
                af = 0.02
            else:
                if low.iloc[i] < ep:
                    ep = low.iloc[i]
                    af = min(af + 0.02, max_af)
    df["SAR"] = sar

    # Volume ratio
    df["VOL_MA20"] = vol.rolling(20).mean()
    df["VOL_RATIO"] = vol / (df["VOL_MA20"] + 1e-9)

    return df

def detect_fractals(df: pd.DataFrame, k: int = 2):
    """Simplified Chanlun fractals (top/bottom)."""
    highs = df["high"]
    lows = df["low"]
    top = (highs.shift(k) < highs) & (highs.shift(-k) < highs)
    bot = (lows.shift(k) > lows) & (lows.shift(-k) > lows)
    df["FRACTAL_TOP"] = top
    df["FRACTAL_BOT"] = bot
    return df

def build_bi_segments(df: pd.DataFrame):
    """Very simplified 'bi' segments connecting alternating fractals."""
    pts = []
    for _, row in df.iterrows():
        if row.get("FRACTAL_TOP"):
            pts.append((row["date"], row["high"], "top"))
        if row.get("FRACTAL_BOT"):
            pts.append((row["date"], row["low"], "bot"))

    segs = []
    last = None
    for p in pts:
        if last is None:
            last = p
            continue
        if p[2] != last[2]:
            segs.append((last, p))
            last = p
        else:
            if p[2] == "top" and p[1] >= last[1]:
                last = p
            if p[2] == "bot" and p[1] <= last[1]:
                last = p
    return segs

def gann_lines(df: pd.DataFrame, pivot_idx: int = None):
    """Simple Gann 1x1, 1x2, 2x1 from pivot low."""
    if pivot_idx is None:
        pivot_idx = df["low"].idxmin()
    pivot_date = df.loc[pivot_idx, "date"]
    pivot_price = df.loc[pivot_idx, "low"]

    days_from_pivot = (df["date"] - pivot_date).dt.days
    step = (df["ATR14"].iloc[-1] or (pivot_price * 0.01))

    lines = {}
    for name, ratio in [("1x1", 1.0), ("1x2", 0.5), ("2x1", 2.0)]:
        y = pivot_price + days_from_pivot * step * ratio
        lines[name] = y
    return lines, pivot_date, pivot_price

def fib_levels(df: pd.DataFrame, lookback: int = 120):
    chunk = df.tail(lookback)
    hi = chunk["high"].max()
    lo = chunk["low"].min()
    diff = hi - lo
    levels = {
        "0.236": hi - diff * 0.236,
        "0.382": hi - diff * 0.382,
        "0.5": hi - diff * 0.5,
        "0.618": hi - diff * 0.618,
        "0.786": hi - diff * 0.786
    }
    return hi, lo, levels

def main_uptrend_state(df: pd.DataFrame):
    latest = df.iloc[-1]
    ma20_slope = df["MA20"].diff().tail(5).mean()
    cloud_top = max(latest["SPAN_A"], latest["SPAN_B"])
    cloud_bot = min(latest["SPAN_A"], latest["SPAN_B"])
    above_cloud = latest["close"] > cloud_top
    adx_strong = latest["ADX"] > 25
    ma_rise = ma20_slope > 0
    if above_cloud and adx_strong and ma_rise:
        return "âœ… ä¸»å‡æµª/å¼ºè¶‹åŠ¿", "success"
    if latest["close"] > cloud_bot and ma_rise:
        return "ğŸŸ¡ è¶‹åŠ¿å­•è‚²ä¸­", "warning"
    return "âŒ éœ‡è¡/ä¸‹è¡Œ", "error"

def make_signals(df: pd.DataFrame):
    latest = df.iloc[-1]
    prev = df.iloc[-2] if len(df) > 1 else latest

    score = 0
    reasons = []

    # Trend / MA
    if latest["MA5"] > latest["MA20"]:
        score += 2; reasons.append("âœ… MA5>MA20ï¼šçŸ­çº¿å¤šå¤´")
    else:
        score -= 2; reasons.append("âŒ MA5<MA20ï¼šçŸ­çº¿å¼±åŠ¿")

    if latest["close"] > latest["MA60"]:
        score += 1; reasons.append("âœ… ç«™ä¸ŠMA60ï¼šä¸­æœŸåå¼º")
    else:
        score -= 1; reasons.append("âŒ è·Œç ´MA60ï¼šä¸­æœŸåå¼±")

    # MACD
    if latest["DIF"] > latest["DEA"] and latest["HIST"] > prev["HIST"]:
        score += 1; reasons.append("âœ… MACDé‡‘å‰ä¸”æŸ±å­æ”¾å¤§")
    elif latest["DIF"] < latest["DEA"]:
        score -= 1; reasons.append("âŒ MACDæ­»å‰/èµ°å¼±")

    # RSI / MFI
    if latest["RSI"] < 30:
        score += 2; reasons.append("ğŸ“‰ RSI<30ï¼šè¶…å–åå¼¹åŒº")
    elif latest["RSI"] > 70:
        score -= 2; reasons.append("ğŸ“ˆ RSI>70ï¼šè¶…ä¹°é£é™©åŒº")

    if latest["MFI"] < 20:
        score += 1; reasons.append("ğŸ’§ MFI<20ï¼šèµ„é‡‘è¿‡åº¦æµå‡ºï¼Œåå¼¹æ¦‚ç‡â†‘")
    elif latest["MFI"] > 80:
        score -= 1; reasons.append("ğŸ’§ MFI>80ï¼šèµ„é‡‘è¿‡çƒ­ï¼Œæ³¨æ„å›æ’¤")

    # ADX
    if latest["ADX"] > 25 and latest["PLUS_DI"] > latest["MINUS_DI"]:
        score += 1; reasons.append("âœ… ADXå¼ºè¶‹åŠ¿ä¸”å¤šå¤´å ä¼˜")
    elif latest["ADX"] > 25:
        score -= 1; reasons.append("âš ï¸ ADXå¼ºè¶‹åŠ¿ä½†ç©ºå¤´å ä¼˜")

    # Bollinger position
    if latest["close"] > latest["Upper"]:
        score -= 1; reasons.append("âš ï¸ çªç ´å¸ƒæ—ä¸Šè½¨ï¼šçŸ­çº¿è¿‡çƒ­")
    elif latest["close"] < latest["Lower"]:
        score += 1; reasons.append("âœ… è·Œç ´å¸ƒæ—ä¸‹è½¨ï¼šæƒ…ç»ªæç«¯")

    # Volume
    if latest["VOL_RATIO"] >= 1.2:
        score += 1; reasons.append("âœ… æ”¾é‡ï¼ˆé‡æ¯”>1.2ï¼‰")
    elif latest["VOL_RATIO"] <= 0.8:
        score -= 1; reasons.append("âŒ ç¼©é‡ï¼ˆé‡æ¯”<0.8ï¼‰")

    # SAR
    if latest["close"] > latest["SAR"]:
        score += 0.5; reasons.append("âœ… SARå¤šå¤´")
    else:
        score -= 0.5; reasons.append("âŒ SARç©ºå¤´")

    # Position suggestion
    if score >= 5:
        action, position, color = "ğŸš€ å¼ºåŠ¿ä¹°å…¥", "70% - 100%", "success"
    elif score >= 3:
        action, position, color = "âœ… è¯•æ¢åŠ ä»“", "30% - 50%", "success"
    elif score >= 0:
        action, position, color = "ğŸ‘€ è§‚æœ›/å°ä»“", "0% - 20%", "warning"
    else:
        action, position, color = "ğŸ›‘ å‡ä»“/æ¸…ä»“", "0% - 10%", "error"

    support = df["low"].tail(20).min()
    resistance = df["high"].tail(20).max()

    # Buy/Sell points (signals)
    buy_signal = (prev["MA5"] <= prev["MA20"]) and (latest["MA5"] > latest["MA20"])
    sell_signal = (prev["MA5"] >= prev["MA20"]) and (latest["MA5"] < latest["MA20"])

    return score, action, position, reasons, support, resistance, color, buy_signal, sell_signal

# -----------------------------
# Plotting
# -----------------------------
def plot_kline(df: pd.DataFrame, title: str,
               show_gann: bool = True,
               show_chanlun: bool = True,
               show_fib: bool = True):
    fig = make_subplots(
        rows=4, cols=1, shared_xaxes=True,
        vertical_spacing=0.02,
        row_heights=[0.55, 0.15, 0.15, 0.15]
    )

    fig.add_trace(go.Candlestick(
        x=df["date"], open=df["open"], high=df["high"],
        low=df["low"], close=df["close"], name="Kçº¿"
    ), row=1, col=1)

    for ma in ["MA5","MA10","MA20","MA60","MA120"]:
        fig.add_trace(go.Scatter(
            x=df["date"], y=df[ma], name=ma, line=dict(width=1)
        ), row=1, col=1)

    # Bollinger
    fig.add_trace(go.Scatter(x=df["date"], y=df["Upper"], name="BOLLä¸Šè½¨",
                             line=dict(dash="dash", width=1)), row=1, col=1)
    fig.add_trace(go.Scatter(x=df["date"], y=df["Lower"], name="BOLLä¸‹è½¨",
                             line=dict(dash="dash", width=1)), row=1, col=1)

    # Ichimoku cloud
    fig.add_trace(go.Scatter(x=df["date"], y=df["SPAN_A"], name="äº‘A", line=dict(width=0.7)),
                  row=1, col=1)
    fig.add_trace(go.Scatter(x=df["date"], y=df["SPAN_B"], name="äº‘B", line=dict(width=0.7)),
                  row=1, col=1)

    # Chanlun fractals + bi
    if show_chanlun:
        tops = df[df["FRACTAL_TOP"]]
        bots = df[df["FRACTAL_BOT"]]
        fig.add_trace(go.Scatter(
            x=tops["date"], y=tops["high"], mode="markers",
            name="ç¼ è®ºé¡¶åˆ†å‹", marker_symbol="triangle-down", marker_size=8
        ), row=1, col=1)
        fig.add_trace(go.Scatter(
            x=bots["date"], y=bots["low"], mode="markers",
            name="ç¼ è®ºåº•åˆ†å‹", marker_symbol="triangle-up", marker_size=8
        ), row=1, col=1)
        segs = build_bi_segments(df)
        for s, e in segs:
            fig.add_trace(go.Scatter(
                x=[s[0], e[0]], y=[s[1], e[1]],
                mode="lines", name="ç¼ è®ºç¬”(ç®€)", line=dict(width=1.2)
            ), row=1, col=1)

    # Gann fan lines
    if show_gann:
        lines, _, _ = gann_lines(df)
        for name, y in lines.items():
            fig.add_trace(go.Scatter(
                x=df["date"], y=y, name=f"æ±Ÿæ©{name}", line=dict(dash="dot", width=1)
            ), row=1, col=1)

    # Fibonacci retracements
    if show_fib:
        _, _, levels = fib_levels(df)
        for k, v in levels.items():
            fig.add_hline(y=v, line_dash="dash", annotation_text=f"Fib {k}",
                          row=1, col=1)

    # Volume
    colors = np.where(df["close"] >= df["open"], "red", "green")
    fig.add_trace(go.Bar(
        x=df["date"], y=df["volume"], name="æˆäº¤é‡", marker_color=colors
    ), row=2, col=1)

    # MACD
    fig.add_trace(go.Scatter(x=df["date"], y=df["DIF"], name="DIF"), row=3, col=1)
    fig.add_trace(go.Scatter(x=df["date"], y=df["DEA"], name="DEA"), row=3, col=1)
    fig.add_trace(go.Bar(x=df["date"], y=df["HIST"], name="MACDæŸ±"), row=3, col=1)

    # RSI / KDJ
    fig.add_trace(go.Scatter(x=df["date"], y=df["RSI"], name="RSI"), row=4, col=1)
    fig.add_trace(go.Scatter(x=df["date"], y=df["K"], name="K"), row=4, col=1)
    fig.add_trace(go.Scatter(x=df["date"], y=df["D"], name="D"), row=4, col=1)

    fig.update_layout(
        title=title,
        xaxis_rangeslider_visible=False,
        height=920,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        margin=dict(t=60, b=30)
    )
    st.plotly_chart(fig, use_container_width=True)

# -----------------------------
# Sidebar controls
# -----------------------------
with st.sidebar:
    st.markdown("## ğŸ›ï¸ æ“ç›˜æ§åˆ¶å° Pro")

    # 1. è¾“å…¥ Token (æ·»åŠ äº†é”™è¯¯å¤„ç†ï¼Œé˜²æ­¢æœ¬åœ°è¿è¡ŒæŠ¥é”™)
    default_token = ""
    try:
        # å°è¯•è¯»å– secretsï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™è·³è¿‡
        if "TUSHARE_TOKEN" in st.secrets:
            default_token = st.secrets["TUSHARE_TOKEN"]
    except Exception:
        pass
    
    tushare_token = st.text_input(
        "TuShare Tokenï¼ˆå¯é€‰ï¼Œç•™ç©ºèµ° Baostockï¼‰",
        value=default_token,
        type="password"
    ).strip()

    # 2. è¾“å…¥ä»£ç 
    stock_code = st.text_input("è‚¡ç¥¨ä»£ç (6ä½)", value="600519").strip()

    # 3. è‡ªåŠ¨åŒ¹é…åç§°
    # å½“ stock_code æ”¹å˜æ—¶ï¼Œé‡æ–°è¿è¡Œ get_stock_name
    auto_name_fetched = get_stock_name(stock_code, tushare_token)
    
    # å¦‚æœæ²¡è·å–åˆ°ï¼Œé»˜è®¤å«â€œæœªçŸ¥è‚¡ç¥¨â€
    default_name = auto_name_fetched if auto_name_fetched else "æœªçŸ¥è‚¡ç¥¨"

    # å…è®¸ç”¨æˆ·æ‰‹åŠ¨ä¿®æ”¹ï¼Œä½†é»˜è®¤å€¼æ˜¯è‡ªåŠ¨è·å–çš„
    stock_name = st.text_input("è‚¡ç¥¨åç§°", value=default_name)

    window_days = st.radio(
        "åˆ†æçª—å£",
        [7, 15, 30, 60, 120, 180],
        index=5,
        horizontal=True
    )

    adjust = st.selectbox(
        "å¤æƒæ–¹å¼",
        ["qfq", "hfq", ""],
        index=0,
        format_func=lambda x: "å‰å¤æƒ" if x == "qfq" else "åå¤æƒ" if x == "hfq" else "ä¸å¤æƒ"
    )

    st.divider()
    st.markdown("### ğŸ“Œ æ˜¾ç¤ºé¡¹")
    show_gann = st.checkbox("æ˜¾ç¤ºæ±Ÿæ©çº¿(ç®€åŒ–)", value=True)
    show_chanlun = st.checkbox("æ˜¾ç¤ºç¼ è®ºåˆ†å‹/ç¬”(ç®€åŒ–)", value=True)
    show_fib = st.checkbox("æ˜¾ç¤ºæ–æ³¢é‚£å¥‘å›æ’¤", value=True)

    st.divider()
    st.markdown("### ğŸ”” å…³é”®ä»·ä½æé†’")
    support_alert = st.number_input("å›è¸©æ”¯æ’‘ä»·ï¼ˆæç¤ºè¡¥ä»“ï¼‰", value=0.0, step=0.1)
    risk_alert = st.number_input("è·Œç ´é£é™©ä»·ï¼ˆæç¤ºå‡ä»“ï¼‰", value=0.0, step=0.1)
    breakout_alert = st.number_input("çªç ´ä»·ï¼ˆæç¤ºåŠ ä»“ï¼‰", value=0.0, step=0.1)

    st.caption("âš ï¸ æ•°æ®æºï¼šTuShare / Baostock è‡ªåŠ¨åˆ‡æ¢")

# -----------------------------
# Main area
# -----------------------------
st.title(f"ğŸ“ˆ {stock_name} ({stock_code}) æ·±åº¦å¤ç›˜ç³»ç»Ÿ Pro")

with st.spinner("æ­£åœ¨æ‹‰å–æ•°æ®..."):
    df = fetch_hist(stock_code, tushare_token, days=380, adjust=adjust)

if df is None or df.empty:
    st.error("æœªè·å–åˆ°æ•°æ®ï¼šå¯èƒ½æ˜¯ä»£ç ä¸å¯¹ / ç½‘ç»œæŠ½é£ / æ¥å£é™æµã€‚")
    st.stop()

df = calc_indicators(df)
df = detect_fractals(df, k=2)

view_df = df.tail(window_days).copy()

latest = view_df.iloc[-1]
prev = view_df.iloc[-2] if len(view_df) > 1 else latest

last_close = float(latest["close"])
prev_close = float(prev["close"])
pct_change = (last_close - prev_close) / prev_close * 100 if prev_close else 0

# Key metrics panel
c1, c2, c3, c4, c5, c6, c7 = st.columns(7)
c1.metric("å½“å‰ä»·æ ¼", f"{last_close:.2f}", f"{pct_change:.2f}%")
c2.metric("RSI(14)", f"{latest['RSI']:.1f}")
c3.metric("MA5", f"{latest['MA5']:.2f}")
c4.metric("MA20", f"{latest['MA20']:.2f}")
c5.metric("MACDæŸ±", f"{latest['HIST']:.3f}")
c6.metric("ADX", f"{latest['ADX']:.1f}", help=">25 å¼ºè¶‹åŠ¿")
c7.metric("é‡æ¯”", f"{latest['VOL_RATIO']:.2f}x")

# Trend state
trend_text, trend_color = main_uptrend_state(view_df)
if trend_color == "success":
    st.success(f"ä¸»å‡æµªè¯†åˆ«ï¼š{trend_text}")
elif trend_color == "warning":
    st.warning(f"ä¸»å‡æµªè¯†åˆ«ï¼š{trend_text}")
else:
    st.error(f"ä¸»å‡æµªè¯†åˆ«ï¼š{trend_text}")

# Chart
plot_kline(view_df, f"{stock_name} | {window_days}æ—¥çª—å£",
           show_gann=show_gann, show_chanlun=show_chanlun, show_fib=show_fib)

# AI signals
score, action, position, reasons, support, resistance, color, buy_sig, sell_sig = make_signals(view_df)

st.subheader("ğŸ¤– AI ä¹°å–ç‚¹ & ä»“ä½å»ºè®®ï¼ˆå¤šæŒ‡æ ‡ç»¼åˆï¼‰")
if color == "success":
    st.success(f"**{action}** | å»ºè®®ä»“ä½ï¼š**{position}**")
elif color == "error":
    st.error(f"**{action}** | å»ºè®®ä»“ä½ï¼š**{position}**")
else:
    st.warning(f"**{action}** | å»ºè®®ä»“ä½ï¼š**{position}**")

# Concrete buy/sell & stop suggestions
atr = latest["ATR14"]
stop_loss = last_close - 2 * atr if pd.notna(atr) else support
take_profit = last_close + 3 * atr if pd.notna(atr) else resistance

scol1, scol2, scol3 = st.columns(3)
scol1.metric("çŸ­çº¿æ­¢æŸå‚è€ƒ(2ATR)", f"{stop_loss:.2f}")
scol2.metric("çŸ­çº¿æ­¢ç›ˆå‚è€ƒ(3ATR)", f"{take_profit:.2f}")
scol3.metric("ç¼ è®ºè¿‘ç«¯æ”¯æ’‘", f"{support:.2f}")

if buy_sig:
    st.success("ğŸ“Œ **çŸ­çº¿ä¹°ç‚¹å‡ºç°ï¼šMA5 ä¸Šç©¿ MA20ï¼ˆé»„é‡‘äº¤å‰ï¼‰**")
if sell_sig:
    st.error("ğŸ“Œ **çŸ­çº¿å–ç‚¹å‡ºç°ï¼šMA5 ä¸‹ç©¿ MA20ï¼ˆæ­»äº¡äº¤å‰ï¼‰**")

st.info(
    f"ğŸ“Œ è¿‘æœŸæ”¯æ’‘ä½ï¼š**{support:.2f}** |  "
    f"å‹åŠ›ä½ï¼š**{resistance:.2f}**"
)

with st.expander("å±•å¼€æŸ¥çœ‹è¯„åˆ†é€»è¾‘ / æŒ‡æ ‡è§£é‡Š"):
    st.write(f"ç»¼åˆè¯„åˆ†ï¼š**{score:.1f}**")
    for r in reasons:
        st.write(r)
    st.markdown("""
**è¯„åˆ†è¯´æ˜ï¼š**
- é‡‡ç”¨å›½é™…é€šç”¨æŒ‡æ ‡ï¼ˆMA/EMAã€MACDã€RSIã€BOLLã€ADXã€MFIã€SARã€KDJã€Ichimokuï¼‰ç»¼åˆæ‰“åˆ†ï¼›
- ç¼ è®ºã€æ±Ÿæ©ã€æ–æ³¢é‚£å¥‘ä¸ºâ€œå½¢æ€/ä½ç½®â€è¾…åŠ©ï¼Œä¸ç›´æ¥å†³å®šä»“ä½ï¼›
- åˆ†å€¼ä»…ç”¨äºæç¤ºæ¦‚ç‡ä¼˜åŠ¿åŒºï¼Œä¸ä¿è¯æ”¶ç›Šã€‚
""")

# Price alerts
if support_alert > 0 and last_close <= support_alert:
    st.warning(f"ğŸŸ¡ å›è¸©æ”¯æ’‘ï¼šè‚¡ä»· â‰¤ {support_alert:.2f}ï¼Œå¯è€ƒè™‘åˆ†æ‰¹è¡¥ä»“")
if risk_alert > 0 and last_close <= risk_alert:
    st.error(f"ğŸ”´ è·Œç ´é£é™©ï¼šè‚¡ä»· â‰¤ {risk_alert:.2f}ï¼Œæ³¨æ„æ§åˆ¶å›æ’¤/å‡ä»“")
if breakout_alert > 0 and last_close >= breakout_alert:
    st.success(f"ğŸŸ¢ çªç ´ç¡®è®¤ï¼šè‚¡ä»· â‰¥ {breakout_alert:.2f}ï¼Œè¶‹åŠ¿ç¡®è®¤å¯åŠ ä»“")
